{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from murel.models.MurelNet import MurelNet\n",
    "from dataset.MurelNetDataset import MurelNetDataset\n",
    "from dataset.ConcatBaselineDataset import ConcatBaselineDataset\n",
    "import yaml\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bat34/venv/lib/python3.5/site-packages/ipykernel_launcher.py:2: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "with open('murel/scripts/murel.yaml') as f:\n",
    "    config = yaml.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = config['ROOT_DIR']\n",
    "config['batch_size'] = 16\n",
    "train_dataset = MurelNetDataset(split=\"train\", \\\n",
    "                                    txt_enc=config['txt_enc'], \\\n",
    "                                    bottom_up_features_dir=config['bottom_up_features_dir'], \\\n",
    "                                    skipthoughts_dir=config['skipthoughts_dir'], \\\n",
    "                                    processed_dir=config['processed_dir'], \\\n",
    "                                    ROOT_DIR=ROOT_DIR, \\\n",
    "                                    vqa_dir=config['vqa_dir'])\n",
    "val_dataset =   MurelNetDataset(split=\"val\", \\\n",
    "                                    txt_enc=config['txt_enc'], \\\n",
    "                                    bottom_up_features_dir=config['bottom_up_features_dir'], \\\n",
    "                                    skipthoughts_dir=config['skipthoughts_dir'], \\\n",
    "                                    processed_dir=config['processed_dir'], \\\n",
    "                                    ROOT_DIR=ROOT_DIR, \\\n",
    "                                    vqa_dir=config['vqa_dir'])\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, \\\n",
    "                              batch_size=config['batch_size'], \\\n",
    "                             num_workers=config['num_workers'], \\\n",
    "                             collate_fn=train_dataset.collate_fn)\n",
    "val_loader = DataLoader(val_dataset, shuffle=True, \\\n",
    "                            batch_size=config['batch_size'], \\\n",
    "                            num_workers=config['num_workers'], \\\n",
    "                            collate_fn=val_dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vocabulary = [word for word, _ in train_dataset.word_to_wid.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MurelNet(config, word_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  193, 11182,  1302,  4840,  1139,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [ 2268,  4583,  5358, 11577, 10864, 11182,  8459,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [11577, 11182, 10554,  6739, 11182,  6044,  8811,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [ 2268,  4583,  3015, 11577,   991, 11182,  8660,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [  193, 11182,  4178,  2224,  1952,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [ 2268,  4583,  3526, 11577, 10864, 11182,  1324,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [10963,  3369,   193, 11182, 10096,  6739, 11182,  7865,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [10963,  6733,  6520, 11182,  7440,  8261,  7586,   193,  3090, 11182,\n",
       "          7928,  8902,  1792],\n",
       "        [10963,  3369,   193, 11182,  5818,  6739,  1632,  6907,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [ 6214,   193,  8290,  8660, 12587,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [10963,  3369,   193, 11182,  3452,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [10963,   193, 11182,  8807,  3090, 11182,  1435,  8902,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [10963, 11577, 11182, 11115,  9456,  8144, 10864, 11182,  5674,     0,\n",
       "             0,     0,     0],\n",
       "        [10963,  1975,  6739,  9959,   193,  1632,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [10963, 11577, 11182,  3526,  8271,  3090,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [10963, 11577, 11182, 12765, 12292,  3090, 11182, 11018,     0,     0,\n",
       "             0,     0,     0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['question_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_enc = model.txt_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "stack(): argument 'tensors' (position 1) must be tuple of Tensors, not Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3b2abb69b5ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mq_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtxt_enc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mq_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtxt_enc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_feats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mq_att\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_feats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mq_att\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_att\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mq_att\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_att\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: stack(): argument 'tensors' (position 1) must be tuple of Tensors, not Tensor"
     ]
    }
   ],
   "source": [
    "q_feats = txt_enc.embedding(torch.stack(data['question_ids']))\n",
    "q_feats, _ = txt_enc.rnn(q_feats)\n",
    "q_att = model.linear0(q_feats)\n",
    "q_att = torch.nn.functional.relu(q_att)\n",
    "q_att = model.linear1(q_att)\n",
    "q_att = dataset.auxiliary_functions.masked_softmax(q_att, torch.stack(data['question_lengths']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = {\\\n",
    "        'question_ids': data['question_ids'].cuda(), \\\n",
    "        'object_features_list': data['object_features_list'].cuda(), \\\n",
    "        'bounding_boxes': data['bounding_boxes'].cuda(), \\\n",
    "        'answer_id': torch.squeeze(data['answer_id']).cuda(), \\\n",
    "        'question_lengths': data['question_lengths'].cuda()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "val_evaluate(model.cuda(), 1, train_loader, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "item = next(iter(murel_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = {\n",
    "    'question_embedding' : torch.randn(2400).unsqueeze(0).expand(2, -1),\n",
    "    'object_features_list' : torch.randn(36, 2048).unsqueeze(0).expand(2, -1, -1),\n",
    "    'bounding_boxes' : torch.randn(36, 4).unsqueeze(0).expand(2, -1, -1)\n",
    "}\n",
    "res = model(item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
