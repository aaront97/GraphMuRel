name: murel_reverse_question_object
checkpoint_option: resume_last  #can be 'best' or 'fresh' or 'resume_last'
ROOT_DIR: '/auto/homes/bat34/VQA_PartII/murel'
bottom_up_features_dir: '/auto/homes/bat34/2018-04-27_bottom-up-attention_fixed_36/'
skipthoughts_dir: '/auto/homes/bat34/VQA_PartII/data/skipthoughts'
processed_dir: '/auto/homes/bat34/VQA_PartII/data/processed_splits'
vqa_dir: '/auto/homes/bat34/VQA'
txt_enc: "BayesianUniSkip"
pooling_agg: 'min'
pairwise_agg: 'max' #Remember to change fusion's pairwise_agg too
batch_size: 256
reduction_factor: 8
grad_clip: 0.25
lr: 0.00005
gradual_warmup_steps: [1.0, 4.0, 7.0] #torch.linspace
lr_decay_epochs: [14, 24, 2] #range
lr_decay_rate: .25
epochs: 25
checkpoint_every: 1
num_workers: 4
load_last_epoch: True
unroll_steps: 3
log_every: 50
fusion_type: block
q_att:
    linear0:
        input_dim: 2400
        output_dim: 512
    linear1: 
        input_dim: 512
        output_dim: 2
fusion:
    pairwise_agg: 'max' 
    obj_features_question:
        type: block
        input_dims: [4800, 2048]
        output_dims: 2048
        dropout_prelin: 0.
        dropout_input: 0.1
        chunks: 20
        rank: 15
        mm_dim: 1000
    box:
        type: block
        input_dims: [4, 4]
        output_dims: 2048
        dropout_prelin: 0.
        dropout_input: 0.
        chunks: 5
        rank: 5
        mm_dim: 200
    obj_features_obj_features:
        type: block
        input_dims: [2048, 2048]
        output_dims: 2048
        dropout_prelin: 0.
        dropout_input: 0.
        chunks: 5
        rank: 5
        mm_dim: 200
    final_fusion:
        type: block
        input_dims: [4800, 2048]
        output_dims: 3000
        dropout_prelin: 0.1
        dropout_input: 0.
        chunks: 20
        rank: 10
        mm_dim: 1600
