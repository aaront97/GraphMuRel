name:  graph_gat3_conv
#name: graph_graph_conv
#name: graph_gcn_conv
checkpoint_option: fresh #can be 'best' or 'fresh' or 'resume_last'
ROOT_DIR: '/auto/homes/bat34/VQA_PartII/models/murel'
checkpoint_dir: '/local/scratch/bat34/murel_trained_models' #'/auto/homes/bat34/VQA_PartII/models/murel/trained_models'
bottom_up_features_dir: '/local/scratch/bat34/2018-04-27_bottom-up-attention_fixed_36/'
skipthoughts_dir: '/auto/homes/bat34/VQA_PartII/data/skipthoughts'
processed_dir: '/auto/homes/bat34/VQA_PartII/data/processed_splits'
graph_type: knn6
include_keys: ['graph_type',
               'seed',
               'loss_function',
               'txt_enc',
               'batch_size',
               'lr',
               'lr_decay_rate',
               'unroll_steps',
               'fusion_type']
vqa_dir: '/auto/homes/bat34/VQA'
txt_enc: "BayesianUniSkip"
pooling_agg: 'max'
pairwise_agg: 'max' #Remember to change fusion's pairwise_agg too
RESULTS_FILE_PATH: '/auto/homes/bat34/VQA_PartII/models/murel/{}.json'
loss_function: 'soft_cross_entropy' # can be soft_cross_entropy or NLLLoss, remember to change RESULTS_FILE_PATH
batch_size: 256
reduction_factor: 8
grad_clip: 0.25
lr: 0.0003 #orig 0.0006
gradual_warmup_steps: [0.5, 2.0, 7.0]  #[1.0, 4.0, 7.0] #torch.linspace
lr_decay_epochs: [14, 24, 2] #range
lr_decay_rate: .25
epochs: 25
checkpoint_every: 1
num_workers: 2
unroll_steps: 3
log_every: 50
seed: 42 # 1337, 42
fusion_type: block
use_graph_module: True
use_pairwise: False
murel_attention: False
murel_cell_attention:
    linear0:
        input_dim: 2048 #fixed
        output_dim: 512
    linear1:
        input_dim: 512
        output_dim: 1
graph:
    graph_layer_type: gatconv #gatconv, gcnconv, graphconv
    graph_type: knn6
    graph_hidden_list: [1024, 512]
    input_dim: 2048 #fixed
    output_dim: 400
q_att:
    linear0:
        input_dim: 2400
        output_dim: 512
    linear1:
        input_dim: 512
        output_dim: 2
fusion:
    pairwise_agg: 'max'
    graph_fusion:
        type: block
        input_dims: [2048, 2048]
        output_dims: 2048
        dropout_prelin: 0.
        dropout_input: 0.
        chunks: 5
        rank: 5
        mm_dim: 200
    obj_features_question:
        type: block
        input_dims: [4800, 2048]
        output_dims: 2048
        dropout_prelin: 0.
        dropout_input: 0.1
        chunks: 20
        rank: 15
        mm_dim: 1000
    box:
        type: block
        input_dims: [4, 4]
        output_dims: 2048
        dropout_prelin: 0.
        dropout_input: 0.
        chunks: 5
        rank: 5
        mm_dim: 200
    obj_features_obj_features:
        type: block
        input_dims: [2048, 2048]
        output_dims: 2048
        dropout_prelin: 0.
        dropout_input: 0.
        chunks: 5
        rank: 5
        mm_dim: 200
    final_fusion:
        type: block
        input_dims: [4800, 400]
        output_dims: 3000 #CHANGE WHEN CHANGING NANS
        dropout_prelin: 0.
        dropout_input: 0.1
        chunks: 20
        rank: 10
        mm_dim: 1600
