{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import json\n",
    "import yaml\n",
    "import tqdm\n",
    "from dataset.ConcatBaselineDataset import ConcatBaselineDataset\n",
    "from baseline.models.ConcatBaselineNet import ConcatBaselineNet\n",
    "from baseline.scripts.train_baseline import get_hidden_layer_list\n",
    "from torch.utils.data import DataLoader\n",
    "import transforms.transforms as trfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2% (9698 of 443757) |                  | Elapsed Time: 0:00:00 ETA:   0:00:08"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing questions for train2014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (443757 of 443757) |################| Elapsed Time: 0:00:10 Time:  0:00:10\n",
      "  3% (8141 of 214354) |                  | Elapsed Time: 0:00:00 ETA:   0:00:04"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing questions for val2014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (214354 of 214354) |################| Elapsed Time: 0:00:05 Time:  0:00:05\n",
      "  2% (10621 of 447793) |                 | Elapsed Time: 0:00:00 ETA:   0:00:08"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing questions for test2015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (447793 of 447793) |################| Elapsed Time: 0:00:09 Time:  0:00:09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of answer_vocabulary: 3000, Original no. of answers: 22531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5% (22469 of 443757) |                 | Elapsed Time: 0:00:00 ETA:  00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of known words: 2752210, No. of unknown words : 1399, Percentage Loss of words: 0.050806051258548326%\n",
      "Removing questions if they have infrequent answers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (443757 of 443757) |################| Elapsed Time: 0:00:01 Time:  0:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving processed datasets...\n",
      "Finished processing annotations and questions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bat34/venv/lib/python3.5/site-packages/ipykernel_launcher.py:13: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  del sys.path[0]\n",
      "/home/bat34/venv/lib/python3.5/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/bat34/venv/lib/python3.5/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConcatBaselineNet(\n",
       "  (hidden): ModuleList(\n",
       "    (0): LayerNorm((4448,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=4448, out_features=3966, bias=True)\n",
       "    (2): Dropout(p=0.25, inplace=False)\n",
       "    (3): LayerNorm((3966,), eps=1e-05, elementwise_affine=True)\n",
       "    (4): Linear(in_features=3966, out_features=3484, bias=True)\n",
       "    (5): Dropout(p=0.25, inplace=False)\n",
       "    (6): LayerNorm((3484,), eps=1e-05, elementwise_affine=True)\n",
       "    (7): Linear(in_features=3484, out_features=3000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = \"/auto/homes/bat34/VQA/\"\n",
    "ROOT_DIR = \"/auto/homes/bat34/VQA_PartII/\"\n",
    "test_dataset = ConcatBaselineDataset(split='test')\n",
    "test_collate_fn = trfm.Compose([\\\n",
    "                              trfm.ConvertBatchListToDict(), \\\n",
    "                              trfm.CreateBatchItem(), \\\n",
    "                              trfm.PrepareBaselineTestBatch() \\\n",
    "            ])\n",
    "\n",
    "\n",
    "\n",
    "with open(os.path.join(ROOT_DIR, 'baseline', 'scripts', 'baseline.yaml')) as f:\n",
    "        config = yaml.load(f)\n",
    "config = config['baseline_options']\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, \\\n",
    "                              batch_size=config['batch_size'], \\\n",
    "                              collate_fn=test_collate_fn,\\\n",
    "                             num_workers=config['num_workers'])\n",
    "input_dim = list(test_dataset[0]['concat_vector'].size())[0]\n",
    "out_dim = len(test_dataset.ans_to_aid)\n",
    "size = config['max_depth']\n",
    "hidden_list = get_hidden_layer_list(input_dim, out_dim, size)\n",
    "model = ConcatBaselineNet(input_dim, out_dim, \\\n",
    "                                  hidden_list, \\\n",
    "                                  dropout=config['dropout'])\n",
    "#Path to model weights with best performance on the validation dataset\n",
    "model.load_state_dict(torch.load(os.path.join(ROOT_DIR, 'baseline', 'trained_models', \\\n",
    "                                   'depth_3_concatbaseline_dropout_0.25_batch_size_1024_lr_0.0001_weight_decay_0_BEST.pth')))\n",
    "model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 438/438 [05:35<00:00,  1.30it/s]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "with torch.no_grad():\n",
    "    for data in tqdm.tqdm(test_loader):\n",
    "        inputs, qids = data[0].cuda(), data[1]\n",
    "        outputs = model(inputs)\n",
    "        values, ans_indices = torch.max(outputs, dim=1)\n",
    "        ans_indices = list(ans_indices)\n",
    "        ans_indices = [tsr.item() for tsr in ans_indices]\n",
    "        for qid, ans_idx in zip(qids, ans_indices):\n",
    "            results.append({\n",
    "                'question_id': int(qid),\n",
    "                'answer': test_dataset.aid_to_ans[ans_idx]\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(ROOT_DIR, 'baseline', 'baseline_test-dev2015_results.json'), 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
