{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import torch\n",
    "import json\n",
    "import yaml\n",
    "import tqdm\n",
    "from baseline.models.AggConcatNet import AggConcatNet\n",
    "from dataset.MurelNetDataset import MurelNetDataset\n",
    "from baseline.models.AttentionNet import AttentionNet\n",
    "from murel.models.MurelNet import MurelNet\n",
    "from torch.utils.data import DataLoader\n",
    "import transforms.transforms as trfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, BEST_MODEL_PATH, RESULTS_FILE_PATH):\n",
    "    #Path to model weights with best performance on the validation dataset\n",
    "    print('Processing %s' % BEST_MODEL_PATH)\n",
    "    model.load_state_dict(torch.load(BEST_MODEL_PATH)['model'])\n",
    "    model = model.cuda()\n",
    "    model = model.eval()\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm.tqdm(test_loader):\n",
    "            item = {\\\n",
    "                'question_ids': data['question_ids'].cuda(), \\\n",
    "                'object_features_list': data['object_features_list'].cuda(), \\\n",
    "                'bounding_boxes': data['bounding_boxes'].cuda(), \\\n",
    "                'question_lengths': data['question_lengths'].cuda(), \\\n",
    "            }\n",
    "            inputs = item\n",
    "            qids = data['question_unique_id']\n",
    "            outputs = model(inputs)\n",
    "            values, ans_indices = torch.max(outputs, dim=1)\n",
    "            ans_indices = list(ans_indices)\n",
    "            ans_indices = [tsr.item() for tsr in ans_indices]\n",
    "            for qid, ans_idx in zip(qids, ans_indices):\n",
    "                results.append({\n",
    "                    'question_id': int(qid),\n",
    "                    'answer': test_dataset.aid_to_ans[ans_idx]\n",
    "                })\n",
    "    print('Saving results to %s' % RESULTS_FILE_PATH)\n",
    "    with open(RESULTS_FILE_PATH, 'w') as f:\n",
    "        json.dump(results, f)\n",
    "    print('Done saving to %s' % RESULTS_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bat34/venv/lib/python3.5/site-packages/ipykernel_launcher.py:7: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Dataset Loaded.\n",
      "val DataLoader loaded.\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"/auto/homes/bat34/VQA/\"\n",
    "ROOT_DIR = \"/auto/homes/bat34/VQA_PartII/\"\n",
    "MODEL_NAME = 'baseline'\n",
    "SPLIT = 'val'\n",
    "CONFIG_PATH = os.path.join(ROOT_DIR, MODEL_NAME, 'scripts', 'attention_baseline' + '.yaml')\n",
    "with open(CONFIG_PATH) as f:\n",
    "        config = yaml.load(f)\n",
    "        \n",
    "train_dataset = MurelNetDataset(split='train', \\\n",
    "                        txt_enc=config['txt_enc'], \\\n",
    "                        bottom_up_features_dir=config['bottom_up_features_dir'], \\\n",
    "                        skipthoughts_dir=config['skipthoughts_dir'], \\\n",
    "                        processed_dir=config['processed_dir'], \\\n",
    "                        ROOT_DIR=ROOT_DIR, \\\n",
    "                        vqa_dir=config['vqa_dir'])\n",
    "\n",
    "test_dataset = MurelNetDataset(split=SPLIT, \\\n",
    "                        txt_enc=config['txt_enc'], \\\n",
    "                        bottom_up_features_dir=config['bottom_up_features_dir'], \\\n",
    "                        skipthoughts_dir=config['skipthoughts_dir'], \\\n",
    "                        processed_dir=config['processed_dir'], \\\n",
    "                        ROOT_DIR=ROOT_DIR, \\\n",
    "                        vqa_dir=config['vqa_dir'])\n",
    "\n",
    "print('{} Dataset Loaded.'.format(SPLIT))\n",
    "\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, \\\n",
    "                         num_workers=config['num_workers'], \\\n",
    "                         batch_size=config['batch_size'] // 4, \\\n",
    "                         collate_fn=test_dataset.collate_fn, \\\n",
    ")\n",
    "\n",
    "print('{} DataLoader loaded.'.format(SPLIT))\n",
    "    \n",
    "word_vocabulary = [word for word, _ in train_dataset.word_to_wid.items()]\n",
    "#model = MurelNet(config, word_vocabulary)\n",
    "model = AttentionNet(config, word_vocabulary)\n",
    "\n",
    "BEST_MODEL_NAME = 'concat_baseline_self_attention_block_txt_enc_BayesianUniSkip_batch_size_256_lr_0.0001_lr_decay_rate_0.25_hidden_list_[1600, 1600]_attention_fusion_type_block_final_fusion_type_block'\n",
    "#BEST_MODEL_NAME = 'murel_reverse_question_object_txt_enc_BayesianUniSkip_batch_size_256_lr_5e-05_lr_decay_rate_0.25_unroll_steps_3_fusion_type_block'\n",
    "#BEST_MODEL_NAME_TEMPL = 'agg_concat_{}_agg_type_{}_q_self_attention_{}' + \\\n",
    "                  #'_txt_enc_BayesianUniSkip_batch_size_256_lr_0.0001_fusion_type_concat_mlp' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /auto/homes/bat34/VQA_PartII/murel/trained_models/best_models/murel_reverse_question_object_txt_enc_BayesianUniSkip_batch_size_256_lr_5e-05_lr_decay_rate_0.25_unroll_steps_3_fusion_type_block/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3350 [00:00<?, ?it/s]/home/bat34/venv/lib/python3.5/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/bat34/venv/lib/python3.5/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "100%|██████████| 3350/3350 [24:04<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to /auto/homes/bat34/VQA_PartII/murel/murel_reverse_question_val-2015_results.json\n",
      "Done saving to /auto/homes/bat34/VQA_PartII/murel/murel_reverse_question_val-2015_results.json\n"
     ]
    }
   ],
   "source": [
    "#BEST_MODEL_NAME = 'murel_reverse_question_object_txt_enc_BayesianUniSkip_pooling_agg_min_pairwise_agg_max_batch_size_256_lr_5e-05_lr_decay_rate_0.25_unroll_steps_3_fusion_type_block'\n",
    "#BEST_MODEL_NAME = 'murel_reverse_question_object_txt_enc_BayesianUniSkip_batch_size_256_lr_5e-05_lr_decay_rate_0.25_unroll_steps_3_fusion_type_block'\n",
    "BEST_MODEL_PATH = os.path.join(ROOT_DIR, MODEL_NAME, 'trained_models', 'best_models', BEST_MODEL_NAME, 'best_model.pth')\n",
    "RES_FILE_NAME = 'attention_{}-2015_results.json'.format(SPLIT)\n",
    "RES_FILE_PATH = os.path.join(ROOT_DIR, MODEL_NAME, RES_FILE_NAME)\n",
    "eval_model(model, BEST_MODEL_PATH, RES_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing agg_concat_mean_agg_type_mean_q_self_attention_True_txt_enc_BayesianUniSkip_batch_size_256_lr_0.0001_fusion_type_concat_mlp....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6997/6997 [21:27<00:00,  5.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to /auto/homes/bat34/VQA_PartII/baseline/agg_mean_q_att_True_test-2015_results.json\n",
      "Done saving to /auto/homes/bat34/VQA_PartII/baseline/agg_mean_q_att_True_test-2015_results.json\n",
      "Processing agg_concat_mean_agg_type_mean_q_self_attention_False_txt_enc_BayesianUniSkip_batch_size_256_lr_0.0001_fusion_type_concat_mlp....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6997/6997 [08:21<00:00, 13.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to /auto/homes/bat34/VQA_PartII/baseline/agg_mean_q_att_False_test-2015_results.json\n",
      "Done saving to /auto/homes/bat34/VQA_PartII/baseline/agg_mean_q_att_False_test-2015_results.json\n",
      "Processing agg_concat_max_agg_type_max_q_self_attention_True_txt_enc_BayesianUniSkip_batch_size_256_lr_0.0001_fusion_type_concat_mlp....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6997/6997 [08:15<00:00, 14.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to /auto/homes/bat34/VQA_PartII/baseline/agg_max_q_att_True_test-2015_results.json\n",
      "Done saving to /auto/homes/bat34/VQA_PartII/baseline/agg_max_q_att_True_test-2015_results.json\n",
      "Processing agg_concat_max_agg_type_max_q_self_attention_False_txt_enc_BayesianUniSkip_batch_size_256_lr_0.0001_fusion_type_concat_mlp....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6997/6997 [08:09<00:00, 14.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to /auto/homes/bat34/VQA_PartII/baseline/agg_max_q_att_False_test-2015_results.json\n",
      "Done saving to /auto/homes/bat34/VQA_PartII/baseline/agg_max_q_att_False_test-2015_results.json\n",
      "Processing agg_concat_min_agg_type_min_q_self_attention_True_txt_enc_BayesianUniSkip_batch_size_256_lr_0.0001_fusion_type_concat_mlp....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6997/6997 [08:00<00:00, 14.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to /auto/homes/bat34/VQA_PartII/baseline/agg_min_q_att_True_test-2015_results.json\n",
      "Done saving to /auto/homes/bat34/VQA_PartII/baseline/agg_min_q_att_True_test-2015_results.json\n",
      "Processing agg_concat_min_agg_type_min_q_self_attention_False_txt_enc_BayesianUniSkip_batch_size_256_lr_0.0001_fusion_type_concat_mlp....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6997/6997 [08:27<00:00, 13.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to /auto/homes/bat34/VQA_PartII/baseline/agg_min_q_att_False_test-2015_results.json\n",
      "Done saving to /auto/homes/bat34/VQA_PartII/baseline/agg_min_q_att_False_test-2015_results.json\n",
      "Processing agg_concat_sum_agg_type_sum_q_self_attention_True_txt_enc_BayesianUniSkip_batch_size_256_lr_0.0001_fusion_type_concat_mlp....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 3939/6997 [04:30<03:03, 16.66it/s]"
     ]
    }
   ],
   "source": [
    "aggs = ['mean', 'max', 'min', 'sum']\n",
    "q_atts = ['True', 'False']\n",
    "\n",
    "for agg in aggs:\n",
    "    for q_att in q_atts:\n",
    "        if q_att == 'True':\n",
    "            config['q_self_attention'] = True\n",
    "            config['fusion_mlp']['input_dims'][0] = 4800\n",
    "        else:\n",
    "            config['q_self_attention'] = False\n",
    "            config['fusion_mlp']['input_dims'][0] = 2400\n",
    "        model = AggConcatNet(config, word_vocabulary)\n",
    "        BEST_MODEL_NAME = BEST_MODEL_NAME_TEMPL.format(agg, agg, q_att)\n",
    "        BEST_MODEL_PATH = os.path.join(ROOT_DIR, MODEL_NAME, 'trained_models', 'best_models', \\\n",
    "                             BEST_MODEL_NAME, 'best_model.pth')\n",
    "        RESULTS_FILE_PATH = os.path.join(ROOT_DIR, MODEL_NAME, 'agg_{}_q_att_{}_test-2015_results.json'.format(agg, q_att))\n",
    "        eval_model(model, BEST_MODEL_PATH, RESULTS_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ROOT_DIR': '/auto/homes/bat34/VQA_PartII/baseline/',\n",
       " 'agg_type': 'min',\n",
       " 'batch_size': 256,\n",
       " 'bottom_up_features_dir': '/auto/homes/bat34/2018-04-27_bottom-up-attention_fixed_36/',\n",
       " 'checkpoint_every': 1,\n",
       " 'checkpoint_option': 'resume_last',\n",
       " 'dropout': 0.2,\n",
       " 'epochs': 25,\n",
       " 'fusion_block': {'chunks': 20,\n",
       "  'dropout_input': 0.1,\n",
       "  'dropout_prelin': 0.0,\n",
       "  'input_dims': [4800, 2048],\n",
       "  'mm_dim': 1000,\n",
       "  'output_dims': 3000,\n",
       "  'rank': 15,\n",
       "  'type': 'block'},\n",
       " 'fusion_mlp': {'dropout': 0.2,\n",
       "  'hidden_list': [3200, 3200],\n",
       "  'input_dims': [4800, 2048],\n",
       "  'out_dim': 3000},\n",
       " 'fusion_type': 'concat_mlp',\n",
       " 'gradual_warmup_steps': [1.0, 4.0, 7.0],\n",
       " 'log_every': 50,\n",
       " 'lr': 0.0001,\n",
       " 'lr_decay_epochs': [14, 24, 2],\n",
       " 'lr_decay_rate': 0.25,\n",
       " 'name': 'agg_concat_min',\n",
       " 'num_workers': 4,\n",
       " 'processed_dir': '/auto/homes/bat34/VQA_PartII/data/processed_splits/',\n",
       " 'q_att': {'q_linear0': {'input_dim': 2400, 'output_dim': 512},\n",
       "  'q_linear1': {'input_dim': 512, 'output_dim': 2}},\n",
       " 'q_self_attention': False,\n",
       " 'reduction_factor': 8,\n",
       " 'skipthoughts_dir': '/auto/homes/bat34/VQA_PartII/data/skipthoughts',\n",
       " 'txt_enc': 'BayesianUniSkip',\n",
       " 'vqa_dir': '/auto/homes/bat34/VQA'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "with torch.no_grad():\n",
    "    for data in tqdm.tqdm(test_loader):\n",
    "        item = {\\\n",
    "            'question_ids': data['question_ids'].cuda(), \\\n",
    "            'object_features_list': data['object_features_list'].cuda(), \\\n",
    "            'bounding_boxes': data['bounding_boxes'].cuda(), \\\n",
    "            'question_lengths': data['question_lengths'].cuda(), \\\n",
    "        }\n",
    "        inputs = item\n",
    "        qids = data['question_unique_id']\n",
    "        outputs = model(inputs)\n",
    "        values, ans_indices = torch.max(outputs, dim=1)\n",
    "        ans_indices = list(ans_indices)\n",
    "        ans_indices = [tsr.item() for tsr in ans_indices]\n",
    "        for qid, ans_idx in zip(qids, ans_indices):\n",
    "            results.append({\n",
    "                'question_id': int(qid),\n",
    "                'answer': test_dataset.aid_to_ans[ans_idx]\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RESULTS_FILE_PATH = os.path.join(ROOT_DIR, MODEL_NAME, '{}_test-2015_results.json'.format(BEST_MODEL_NAME))\n",
    "RESULTS_FILE_PATH = os.path.join(ROOT_DIR, MODEL_NAME, 'baseline_self_attention_block_test-2015_results.json')\n",
    "with open(RESULTS_FILE_PATH, 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_FILE_PATH = os.path.join(ROOT_DIR, MODEL_NAME, '{}_test-2015_results.json'.format(BEST_MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
