{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import torch\n",
    "import json\n",
    "import yaml\n",
    "import tqdm\n",
    "from baseline.models.AggConcatNet import AggConcatNet\n",
    "from dataset.MurelNetDataset import MurelNetDataset\n",
    "from baseline.models.AttentionNet import AttentionNet\n",
    "from murel.models.MurelNet import MurelNet\n",
    "from torch.utils.data import DataLoader\n",
    "import transforms.transforms as trfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, BEST_MODEL_PATH, RESULTS_FILE_PATH):\n",
    "    #Path to model weights with best performance on the validation dataset\n",
    "    print('Processing %s' % BEST_MODEL_PATH)\n",
    "    model.load_state_dict(torch.load(BEST_MODEL_PATH)['model'])\n",
    "    model = model.cuda()\n",
    "    model = model.eval()\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm.tqdm(test_loader):\n",
    "            item = {\\\n",
    "                'question_ids': data['question_ids'].cuda(), \\\n",
    "                'object_features_list': data['object_features_list'].cuda(), \\\n",
    "                'bounding_boxes': data['bounding_boxes'].cuda(), \\\n",
    "                'question_lengths': data['question_lengths'].cuda(), \\\n",
    "            }\n",
    "            inputs = item\n",
    "            qids = data['question_unique_id']\n",
    "            outputs = model(inputs)\n",
    "            values, ans_indices = torch.max(outputs, dim=1)\n",
    "            ans_indices = list(ans_indices)\n",
    "            ans_indices = [tsr.item() for tsr in ans_indices]\n",
    "            for qid, ans_idx in zip(qids, ans_indices):\n",
    "                results.append({\n",
    "                    'question_id': int(qid),\n",
    "                    'answer': test_dataset.aid_to_ans[ans_idx]\n",
    "                })\n",
    "    print('Saving results to %s' % RESULTS_FILE_PATH)\n",
    "    with open(RESULTS_FILE_PATH, 'w') as f:\n",
    "        json.dump(results, f)\n",
    "    print('Done saving to %s' % RESULTS_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bat34/venv/lib/python3.5/site-packages/ipykernel_launcher.py:7: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Dataset Loaded.\n",
      "val DataLoader loaded.\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"/auto/homes/bat34/VQA/\"\n",
    "ROOT_DIR = \"/auto/homes/bat34/VQA_PartII/\"\n",
    "MODEL_NAME = 'baseline'\n",
    "SPLIT = 'val'\n",
    "CONFIG_PATH = os.path.join(ROOT_DIR, MODEL_NAME, 'scripts', 'attention_baseline' + '.yaml')\n",
    "with open(CONFIG_PATH) as f:\n",
    "        config = yaml.load(f)\n",
    "        \n",
    "train_dataset = MurelNetDataset(split='train', \\\n",
    "                        txt_enc=config['txt_enc'], \\\n",
    "                        bottom_up_features_dir=config['bottom_up_features_dir'], \\\n",
    "                        skipthoughts_dir=config['skipthoughts_dir'], \\\n",
    "                        processed_dir=config['processed_dir'], \\\n",
    "                        ROOT_DIR=ROOT_DIR, \\\n",
    "                        vqa_dir=config['vqa_dir'])\n",
    "\n",
    "test_dataset = MurelNetDataset(split=SPLIT, \\\n",
    "                        txt_enc=config['txt_enc'], \\\n",
    "                        bottom_up_features_dir=config['bottom_up_features_dir'], \\\n",
    "                        skipthoughts_dir=config['skipthoughts_dir'], \\\n",
    "                        processed_dir=config['processed_dir'], \\\n",
    "                        ROOT_DIR=ROOT_DIR, \\\n",
    "                        vqa_dir=config['vqa_dir'])\n",
    "\n",
    "print('{} Dataset Loaded.'.format(SPLIT))\n",
    "\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, \\\n",
    "                         num_workers=config['num_workers'], \\\n",
    "                         batch_size=config['batch_size'] // 4, \\\n",
    "                         collate_fn=test_dataset.collate_fn, \\\n",
    ")\n",
    "\n",
    "print('{} DataLoader loaded.'.format(SPLIT))\n",
    "    \n",
    "word_vocabulary = [word for word, _ in train_dataset.word_to_wid.items()]\n",
    "#model = MurelNet(config, word_vocabulary)\n",
    "model = AttentionNet(config, word_vocabulary)\n",
    "\n",
    "BEST_MODEL_NAME = 'concat_baseline_self_attention_block_txt_enc_BayesianUniSkip_batch_size_256_lr_0.0001_lr_decay_rate_0.25_hidden_list_[1600, 1600]_attention_fusion_type_block_final_fusion_type_block'\n",
    "#BEST_MODEL_NAME = 'murel_reverse_question_object_txt_enc_BayesianUniSkip_batch_size_256_lr_5e-05_lr_decay_rate_0.25_unroll_steps_3_fusion_type_block'\n",
    "#BEST_MODEL_NAME_TEMPL = 'agg_concat_{}_agg_type_{}_q_self_attention_{}' + \\\n",
    "                  #'_txt_enc_BayesianUniSkip_batch_size_256_lr_0.0001_fusion_type_concat_mlp' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, shuffle=False, \\\n",
    "                         num_workers=config['num_workers'], \\\n",
    "                         batch_size=config['batch_size'] // 4, \\\n",
    "                         collate_fn=train_dataset.collate_fn, \\\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.eval_vqa import VQA_Evaluator\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading VQA annotations and questions into memory...\n",
      "0:00:03.292408\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "evaluator = VQA_Evaluator(summary_writer=SummaryWriter(logdir='/auto/homes/bat34/test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from murel.scripts.murel_train import val_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = MurelNetDataset(split='val', \\\n",
    "                        txt_enc=config['txt_enc'], \\\n",
    "                        bottom_up_features_dir=config['bottom_up_features_dir'], \\\n",
    "                        skipthoughts_dir=config['skipthoughts_dir'], \\\n",
    "                        processed_dir=config['processed_dir'], \\\n",
    "                        ROOT_DIR=ROOT_DIR, \\\n",
    "                        vqa_dir=config['vqa_dir'])\n",
    "val_loader = DataLoader(val_dataset, shuffle=False, \\\n",
    "                         num_workers=config['num_workers'], \\\n",
    "                         batch_size=config['batch_size'] // 4, \\\n",
    "                         collate_fn=val_dataset.collate_fn, \\\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_FILE_PATH = '/auto/homes/bat34/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttentionNet(\n",
       "  (attention_fusion): Block(\n",
       "    (linear0): Linear(in_features=4800, out_features=1000, bias=True)\n",
       "    (linear1): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "    (merge_linears0): ModuleList(\n",
       "      (0): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (1): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (2): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (3): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (4): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (5): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (6): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (7): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (8): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (9): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (10): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (11): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (12): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (13): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (14): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (15): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (16): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (17): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (18): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (19): Linear(in_features=50, out_features=750, bias=True)\n",
       "    )\n",
       "    (merge_linears1): ModuleList(\n",
       "      (0): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (1): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (2): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (3): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (4): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (5): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (6): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (7): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (8): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (9): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (10): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (11): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (12): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (13): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (14): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (15): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (16): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (17): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (18): Linear(in_features=50, out_features=750, bias=True)\n",
       "      (19): Linear(in_features=50, out_features=750, bias=True)\n",
       "    )\n",
       "    (linear_out): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "  )\n",
       "  (final_fusion): Block(\n",
       "    (linear0): Linear(in_features=4800, out_features=1000, bias=True)\n",
       "    (linear1): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "    (merge_linears0): ModuleList(\n",
       "      (0): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (1): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (2): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (3): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (4): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (5): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (6): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (7): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (8): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (9): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (10): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (11): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (12): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (13): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (14): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (15): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (16): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (17): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (18): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (19): Linear(in_features=50, out_features=500, bias=True)\n",
       "    )\n",
       "    (merge_linears1): ModuleList(\n",
       "      (0): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (1): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (2): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (3): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (4): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (5): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (6): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (7): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (8): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (9): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (10): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (11): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (12): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (13): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (14): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (15): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (16): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (17): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (18): Linear(in_features=50, out_features=500, bias=True)\n",
       "      (19): Linear(in_features=50, out_features=500, bias=True)\n",
       "    )\n",
       "    (linear_out): Linear(in_features=1000, out_features=3000, bias=True)\n",
       "  )\n",
       "  (txt_enc): BayesianUniSkip(\n",
       "    (embedding): Embedding(12839, 620, padding_idx=0)\n",
       "    (rnn): BayesianGRU(\n",
       "      (gru_cell): BayesianGRUCell(\n",
       "        (weight_ir): Linear(in_features=620, out_features=2400, bias=True)\n",
       "        (weight_ii): Linear(in_features=620, out_features=2400, bias=True)\n",
       "        (weight_in): Linear(in_features=620, out_features=2400, bias=True)\n",
       "        (weight_hr): Linear(in_features=2400, out_features=2400, bias=False)\n",
       "        (weight_hi): Linear(in_features=2400, out_features=2400, bias=False)\n",
       "        (weight_hn): Linear(in_features=2400, out_features=2400, bias=False)\n",
       "        (drop_ir): SequentialDropout(0.2500)\n",
       "        (drop_ii): SequentialDropout(0.2500)\n",
       "        (drop_in): SequentialDropout(0.2500)\n",
       "        (drop_hr): SequentialDropout(0.2500)\n",
       "        (drop_hi): SequentialDropout(0.2500)\n",
       "        (drop_hn): SequentialDropout(0.2500)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (q_linear0): Linear(in_features=2400, out_features=512, bias=True)\n",
       "  (q_linear1): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (obj_linear0): Linear(in_features=1000, out_features=512, bias=True)\n",
       "  (obj_linear1): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (log_softmax): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3350 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model on validation dataset..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3350 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'VQA_Evaluator' object does not support indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-203-67bf2eac250b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/auto/homes/bat34/test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maid_to_ans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRESULTS_FILE_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/auto/homes/bat34/VQA_PartII/murel/scripts/murel_train.py\u001b[0m in \u001b[0;36mval_evaluate\u001b[0;34m(model, epoch, val_loader, writer, evaluator, aid_to_ans, RESULTS_FILE_PATH)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 results.append({\n\u001b[1;32m     55\u001b[0m                     \u001b[0;34m'question_id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                     \u001b[0;34m'answer'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maid_to_ans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mans_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                 })\n\u001b[1;32m     58\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Saving results to %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mRESULTS_FILE_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'VQA_Evaluator' object does not support indexing"
     ]
    }
   ],
   "source": [
    "accuracy = val_evaluate(model, 0, val_loader, SummaryWriter(logdir='/auto/homes/bat34/test'), evaluator, train_dataset.aid_to_ans, RESULTS_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /auto/homes/bat34/VQA_PartII/baseline/trained_models/best_models/concat_baseline_self_attention_block_txt_enc_BayesianUniSkip_batch_size_256_lr_0.0001_lr_decay_rate_0.25_hidden_list_[1600, 1600]_attention_fusion_type_block_final_fusion_type_block/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3350/3350 [10:26<00:00,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to /auto/homes/bat34/VQA_PartII/baseline/attention_block_val-2015_results.json\n",
      "Done saving to /auto/homes/bat34/VQA_PartII/baseline/attention_block_val-2015_results.json\n"
     ]
    }
   ],
   "source": [
    "#BEST_MODEL_NAME = 'murel_reverse_question_object_txt_enc_BayesianUniSkip_pooling_agg_min_pairwise_agg_max_batch_size_256_lr_5e-05_lr_decay_rate_0.25_unroll_steps_3_fusion_type_block'\n",
    "#BEST_MODEL_NAME = 'murel_reverse_question_object_txt_enc_BayesianUniSkip_batch_size_256_lr_5e-05_lr_decay_rate_0.25_unroll_steps_3_fusion_type_block'\n",
    "BEST_MODEL_PATH = os.path.join(ROOT_DIR, MODEL_NAME, 'trained_models', 'best_models', BEST_MODEL_NAME, 'best_model.pth')\n",
    "RES_FILE_NAME = 'attention_block_{}-2015_results.json'.format(SPLIT)\n",
    "RES_FILE_PATH = os.path.join(ROOT_DIR, MODEL_NAME, RES_FILE_NAME)\n",
    "eval_model(model, BEST_MODEL_PATH, RES_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing agg_concat_mean_agg_type_mean_q_self_attention_True_txt_enc_BayesianUniSkip_batch_size_256_lr_0.0001_fusion_type_concat_mlp....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6997/6997 [21:27<00:00,  5.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to /auto/homes/bat34/VQA_PartII/baseline/agg_mean_q_att_True_test-2015_results.json\n",
      "Done saving to /auto/homes/bat34/VQA_PartII/baseline/agg_mean_q_att_True_test-2015_results.json\n",
      "Processing agg_concat_mean_agg_type_mean_q_self_attention_False_txt_enc_BayesianUniSkip_batch_size_256_lr_0.0001_fusion_type_concat_mlp....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6997/6997 [08:21<00:00, 13.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to /auto/homes/bat34/VQA_PartII/baseline/agg_mean_q_att_False_test-2015_results.json\n",
      "Done saving to /auto/homes/bat34/VQA_PartII/baseline/agg_mean_q_att_False_test-2015_results.json\n",
      "Processing agg_concat_max_agg_type_max_q_self_attention_True_txt_enc_BayesianUniSkip_batch_size_256_lr_0.0001_fusion_type_concat_mlp....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6997/6997 [08:15<00:00, 14.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to /auto/homes/bat34/VQA_PartII/baseline/agg_max_q_att_True_test-2015_results.json\n",
      "Done saving to /auto/homes/bat34/VQA_PartII/baseline/agg_max_q_att_True_test-2015_results.json\n",
      "Processing agg_concat_max_agg_type_max_q_self_attention_False_txt_enc_BayesianUniSkip_batch_size_256_lr_0.0001_fusion_type_concat_mlp....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6997/6997 [08:09<00:00, 14.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to /auto/homes/bat34/VQA_PartII/baseline/agg_max_q_att_False_test-2015_results.json\n",
      "Done saving to /auto/homes/bat34/VQA_PartII/baseline/agg_max_q_att_False_test-2015_results.json\n",
      "Processing agg_concat_min_agg_type_min_q_self_attention_True_txt_enc_BayesianUniSkip_batch_size_256_lr_0.0001_fusion_type_concat_mlp....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6997/6997 [08:00<00:00, 14.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to /auto/homes/bat34/VQA_PartII/baseline/agg_min_q_att_True_test-2015_results.json\n",
      "Done saving to /auto/homes/bat34/VQA_PartII/baseline/agg_min_q_att_True_test-2015_results.json\n",
      "Processing agg_concat_min_agg_type_min_q_self_attention_False_txt_enc_BayesianUniSkip_batch_size_256_lr_0.0001_fusion_type_concat_mlp....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6997/6997 [08:27<00:00, 13.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to /auto/homes/bat34/VQA_PartII/baseline/agg_min_q_att_False_test-2015_results.json\n",
      "Done saving to /auto/homes/bat34/VQA_PartII/baseline/agg_min_q_att_False_test-2015_results.json\n",
      "Processing agg_concat_sum_agg_type_sum_q_self_attention_True_txt_enc_BayesianUniSkip_batch_size_256_lr_0.0001_fusion_type_concat_mlp....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 3939/6997 [04:30<03:03, 16.66it/s]"
     ]
    }
   ],
   "source": [
    "aggs = ['mean', 'max', 'min', 'sum']\n",
    "q_atts = ['True', 'False']\n",
    "\n",
    "for agg in aggs:\n",
    "    for q_att in q_atts:\n",
    "        if q_att == 'True':\n",
    "            config['q_self_attention'] = True\n",
    "            config['fusion_mlp']['input_dims'][0] = 4800\n",
    "        else:\n",
    "            config['q_self_attention'] = False\n",
    "            config['fusion_mlp']['input_dims'][0] = 2400\n",
    "        model = AggConcatNet(config, word_vocabulary)\n",
    "        BEST_MODEL_NAME = BEST_MODEL_NAME_TEMPL.format(agg, agg, q_att)\n",
    "        BEST_MODEL_PATH = os.path.join(ROOT_DIR, MODEL_NAME, 'trained_models', 'best_models', \\\n",
    "                             BEST_MODEL_NAME, 'best_model.pth')\n",
    "        RESULTS_FILE_PATH = os.path.join(ROOT_DIR, MODEL_NAME, 'agg_{}_q_att_{}_test-2015_results.json'.format(agg, q_att))\n",
    "        eval_model(model, BEST_MODEL_PATH, RESULTS_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "with torch.no_grad():\n",
    "    for data in tqdm.tqdm(test_loader):\n",
    "        item = {\\\n",
    "            'question_ids': data['question_ids'].cuda(), \\\n",
    "            'object_features_list': data['object_features_list'].cuda(), \\\n",
    "            'bounding_boxes': data['bounding_boxes'].cuda(), \\\n",
    "            'question_lengths': data['question_lengths'].cuda(), \\\n",
    "        }\n",
    "        inputs = item\n",
    "        qids = data['question_unique_id']\n",
    "        outputs = model(inputs)\n",
    "        values, ans_indices = torch.max(outputs, dim=1)\n",
    "        ans_indices = list(ans_indices)\n",
    "        ans_indices = [tsr.item() for tsr in ans_indices]\n",
    "        for qid, ans_idx in zip(qids, ans_indices):\n",
    "            results.append({\n",
    "                'question_id': int(qid),\n",
    "                'answer': test_dataset.aid_to_ans[ans_idx]\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RESULTS_FILE_PATH = os.path.join(ROOT_DIR, MODEL_NAME, '{}_test-2015_results.json'.format(BEST_MODEL_NAME))\n",
    "RESULTS_FILE_PATH = os.path.join(ROOT_DIR, MODEL_NAME, 'baseline_self_attention_block_test-2015_results.json')\n",
    "with open(RESULTS_FILE_PATH, 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_FILE_PATH = os.path.join(ROOT_DIR, MODEL_NAME, '{}_test-2015_results.json'.format(BEST_MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
