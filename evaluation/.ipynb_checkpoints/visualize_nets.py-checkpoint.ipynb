{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "from models.murel.networks.MurelNet import MurelNet\n",
    "from dataset.VQAv2Dataset import VQAv2Dataset\n",
    "import yaml\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bat34/venv/lib/python3.5/site-packages/ipykernel_launcher.py:2: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "with open('../models/murel/configs/murel.yaml') as f:\n",
    "    config = yaml.load(f)\n",
    "\n",
    "    \n",
    "train_dataset = VQAv2Dataset(split=\"train\",\n",
    "                            txt_enc=config['txt_enc'],\n",
    "                            bottom_up_features_dir=config['bottom_up_features_dir'],\n",
    "                            skipthoughts_dir=config['skipthoughts_dir'],\n",
    "                            processed_dir=config['processed_dir'],\n",
    "                            ROOT_DIR=config['ROOT_DIR'],\n",
    "                            vqa_dir=config['vqa_dir'])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          shuffle=False,\n",
    "                          batch_size=1,\n",
    "                          num_workers=config['num_workers'],\n",
    "                          collate_fn=train_dataset.collate_fn)\n",
    "\n",
    "train_iter = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['fusion']['final_fusion']['output_dims'] = 3000\n",
    "model = MurelNet(config, train_dataset.wid_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = 'murel_dropout_seed_1337_loss_function_NLLLoss_txt_enc_BayesianUniSkip_pooling_agg_max_pairwise_agg_max_batch_size_256_lr_0.0003_lr_decay_rate_0.25_unroll_steps_3_fusion_type_block'\n",
    "x = torch.load('../models/murel/trained_models/best_models/{}/best_model.pth'.format(best_model_name))\n",
    "model.load_state_dict(x['model'])\n",
    "model.initialise_buffers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct question\n",
    "question_reconstr = [train_dataset.wid_to_word[id.item()] for id in list(data['question_ids'])[0]]\n",
    "question_reconstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('/home/bat34/VQA/visualise_images/{}'.format(data['image_name'][0]), cv2.IMREAD_COLOR)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.initialise_buffers()\n",
    "with torch.no_grad():\n",
    "    output = model(data)\n",
    "buffer = model.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img = img.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounding_boxes = data['bounding_boxes'].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bb in bounding_boxes:\n",
    "    x1, y1, x2, y2 = bb\n",
    "    x1, x2 = int(x1 * img.shape[1]), int(x2 * img.shape[1])\n",
    "    y1, y2 = int(y1 * img.shape[0]), int(y2 * img.shape[0])\n",
    "    new_img = cv2.rectangle(new_img, (x1, y1), (x2, y2), (255, 255, 255), 2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(new_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, arg = torch.max(output, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.aid_to_ans[arg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr = buffer[0]['argmax'].tolist()[0][0]\n",
    "\n",
    "curr_count = Counter(curr)\n",
    "\n",
    "new_img = img.copy()\n",
    "for i, bb in enumerate(bounding_boxes):\n",
    "    x1, y1, x2, y2 = bb\n",
    "    x1, x2 = int(x1 * img.shape[1]), int(x2 * img.shape[1])\n",
    "    y1, y2 = int(y1 * img.shape[0]), int(y2 * img.shape[0])\n",
    "    sub_img = img[y1: y2 - y1, x1: x2 - x1]\n",
    "    white_rect = np.ones(sub_img.shape, dtype=np.uint8) * 255\n",
    "    res = cv2.addWeighted(sub_img, 0.8, white_rect, curr_count[i]/2048, 1.0)\n",
    "    new_img[y1:y2 - y1, x1: x2 - x1] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(new_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr = buffer[1]['argmax'].tolist()[0][0]\n",
    "\n",
    "curr_count = Counter(curr)\n",
    "\n",
    "new_img = img.copy()\n",
    "for i, bb in enumerate(bounding_boxes):\n",
    "    x1, y1, x2, y2 = bb\n",
    "    x1, x2 = int(x1 * img.shape[1]), int(x2 * img.shape[1])\n",
    "    y1, y2 = int(y1 * img.shape[0]), int(y2 * img.shape[0])\n",
    "    sub_img = img[y1: y2 - y1, x1: x2 - x1]\n",
    "    white_rect = np.ones(sub_img.shape, dtype=np.uint8) * 255\n",
    "    res = cv2.addWeighted(sub_img, 0.8, white_rect, curr_count[i]/2048, 1.0)\n",
    "    new_img[y1:y2 - y1, x1: x2 - x1] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(new_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr = buffer[2]['argmax'].tolist()[0][0]\n",
    "\n",
    "curr_count = Counter(curr)\n",
    "\n",
    "new_img = img.copy()\n",
    "for i, bb in enumerate(bounding_boxes):\n",
    "    x1, y1, x2, y2 = bb\n",
    "    x1, x2 = int(x1 * img.shape[1]), int(x2 * img.shape[1])\n",
    "    y1, y2 = int(y1 * img.shape[0]), int(y2 * img.shape[0])\n",
    "    sub_img = img[y1: y2 - y1, x1: x2 - x1]\n",
    "    white_rect = np.ones(sub_img.shape, dtype=np.uint8) * 255\n",
    "    res = cv2.addWeighted(sub_img, 0.8, white_rect, curr_count[i]/2048, 1.0)\n",
    "    new_img[y1:y2 - y1, x1: x2 - x1] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(new_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
