{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import torch\n",
    "import json\n",
    "import yaml\n",
    "import tqdm\n",
    "from dataset.ConcatBaselineDataset import ConcatBaselineDataset\n",
    "from baseline.models.ConcatBaselineNet import ConcatBaselineNet\n",
    "from dataset.MurelNetDataset import MurelNetDataset\n",
    "from murel.models.MurelNet import MurelNet\n",
    "from baseline.scripts.train_baseline import get_hidden_layer_list\n",
    "from torch.utils.data import DataLoader\n",
    "import transforms.transforms as trfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bat34/venv/lib/python3.5/site-packages/ipykernel_launcher.py:6: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"/auto/homes/bat34/VQA/\"\n",
    "ROOT_DIR = \"/auto/homes/bat34/VQA_PartII/\"\n",
    "MODEL_NAME = 'baseline'\n",
    "CONFIG_PATH = os.path.join(ROOT_DIR, MODEL_NAME, 'scripts', MODEL_NAME + '.yaml')\n",
    "with open(CONFIG_PATH) as f:\n",
    "        config = yaml.load(f)\n",
    "        \n",
    "train_dataset = MurelNetDataset(split='train', \\\n",
    "                        txt_enc=config['txt_enc'], \\\n",
    "                        bottom_up_features_dir=config['bottom_up_features_dir'], \\\n",
    "                        skipthoughts_dir=config['skipthoughts_dir'], \\\n",
    "                        processed_dir=config['processed_dir'], \\\n",
    "                        ROOT_DIR=ROOT_DIR, \\\n",
    "                        vqa_dir=config['vqa_dir'])\n",
    "\n",
    "test_dataset = MurelNetDataset(split='test', \\\n",
    "                        txt_enc=config['txt_enc'], \\\n",
    "                        bottom_up_features_dir=config['bottom_up_features_dir'], \\\n",
    "                        skipthoughts_dir=config['skipthoughts_dir'], \\\n",
    "                        processed_dir=config['processed_dir'], \\\n",
    "                        ROOT_DIR=ROOT_DIR, \\\n",
    "                        vqa_dir=config['vqa_dir'])\n",
    "\n",
    "\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, \\\n",
    "                         num_workers=config['num_workers'], \\\n",
    "                         batch_size=config['batch_size'], \\\n",
    "                         collate_fn=test_dataset.collate_fn, \\\n",
    ")\n",
    "    \n",
    "word_vocabulary = [word for word, _ in train_dataset.word_to_wid.items()]\n",
    "#model = MurelNet(config, word_vocabulary)\n",
    "model = ConcatBaselineNet(config, word_vocabulary)\n",
    "\n",
    "BEST_MODEL_NAME = 'concat_baseline_self_attention_txt_enc_BayesianUniSkip_batch_size_256_lr_0.0001_lr_decay_rate_0.25_hidden_list_[1600, 1600]'\n",
    "BEST_MODEL_PATH = os.path.join(ROOT_DIR, MODEL_NAME, 'trained_models', 'best_models', \\\n",
    "                             BEST_MODEL_NAME, 'best_model.pth')\n",
    "\n",
    "#Path to model weights with best performance on the validation dataset\n",
    "model.load_state_dict(torch.load(BEST_MODEL_PATH)['model'])\n",
    "model = model.cuda()\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1750/1750 [32:47<00:00,  1.12s/it] \n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "with torch.no_grad():\n",
    "    for data in tqdm.tqdm(test_loader):\n",
    "        item = {\\\n",
    "            'question_ids': data['question_ids'].cuda(), \\\n",
    "            'object_features_list': data['object_features_list'].cuda(), \\\n",
    "            'bounding_boxes': data['bounding_boxes'].cuda(), \\\n",
    "            'question_lengths': data['question_lengths'].cuda(), \\\n",
    "        }\n",
    "        inputs = item\n",
    "        qids = data['question_unique_id']\n",
    "        outputs = model(inputs)\n",
    "        values, ans_indices = torch.max(outputs, dim=1)\n",
    "        ans_indices = list(ans_indices)\n",
    "        ans_indices = [tsr.item() for tsr in ans_indices]\n",
    "        for qid, ans_idx in zip(qids, ans_indices):\n",
    "            results.append({\n",
    "                'question_id': int(qid),\n",
    "                'answer': test_dataset.aid_to_ans[ans_idx]\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = 1\n",
    "RESULTS_FILE_PATH = os.path.join(ROOT_DIR, MODEL_NAME, '{}_test-2015_results_{}.json'.format(MODEL_NAME, ID))\n",
    "with open(RESULTS_FILE_PATH, 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
