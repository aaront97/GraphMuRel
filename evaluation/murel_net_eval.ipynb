{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import torch\n",
    "import json\n",
    "import yaml\n",
    "import tqdm\n",
    "from baseline.models.AggConcatNet import AggConcatNet\n",
    "from dataset.MurelNetDataset import MurelNetDataset\n",
    "from baseline.models.AttentionNet import AttentionNet\n",
    "from murel.models.MurelNet import MurelNet\n",
    "from torch.utils.data import DataLoader\n",
    "import transforms.transforms as trfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, BEST_MODEL_PATH, RESULTS_FILE_PATH):\n",
    "    #Path to model weights with best performance on the validation dataset\n",
    "    print('Processing %s' % BEST_MODEL_PATH)\n",
    "    model.load_state_dict(torch.load(BEST_MODEL_PATH)['model'])\n",
    "    model = model.cuda()\n",
    "    model = model.eval()\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm.tqdm(test_loader):\n",
    "            item = {\\\n",
    "                'question_ids': data['question_ids'].cuda(), \\\n",
    "                'object_features_list': data['object_features_list'].cuda(), \\\n",
    "                'bounding_boxes': data['bounding_boxes'].cuda(), \\\n",
    "                'question_lengths': data['question_lengths'].cuda(), \\\n",
    "            }\n",
    "            inputs = item\n",
    "            qids = data['question_unique_id']\n",
    "            outputs = model(inputs)\n",
    "            values, ans_indices = torch.max(outputs, dim=1)\n",
    "            ans_indices = list(ans_indices)\n",
    "            ans_indices = [tsr.item() for tsr in ans_indices]\n",
    "            for qid, ans_idx in zip(qids, ans_indices):\n",
    "                results.append({\n",
    "                    'question_id': int(qid),\n",
    "                    'answer': test_dataset.aid_to_ans[ans_idx]\n",
    "                })\n",
    "    print('Saving results to %s' % RESULTS_FILE_PATH)\n",
    "    with open(RESULTS_FILE_PATH, 'w') as f:\n",
    "        json.dump(results, f)\n",
    "    print('Done saving to %s' % RESULTS_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bat34/venv/lib/python3.5/site-packages/ipykernel_launcher.py:7: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  import sys\n",
      "  1% (4785 of 443757) |                  | Elapsed Time: 0:00:00 ETA:   0:00:09"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing questions for train2014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (443757 of 443757) |################| Elapsed Time: 0:00:09 Time:  0:00:09\n",
      "  2% (5427 of 214354) |                  | Elapsed Time: 0:00:00 ETA:   0:00:04"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing questions for val2014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (214354 of 214354) |################| Elapsed Time: 0:00:04 Time:  0:00:04\n",
      "  1% (5329 of 447793) |                  | Elapsed Time: 0:00:00 ETA:   0:00:08"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing questions for test2015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (447793 of 447793) |################| Elapsed Time: 0:00:08 Time:  0:00:08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of answer_vocabulary: 3000, Original no. of answers: 22531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5% (22469 of 443757) |                 | Elapsed Time: 0:00:00 ETA:  00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of known words: 2752210, No. of unknown words : 1399, Percentage Loss of words: 0.050806051258548326%\n",
      "Removing questions if they have infrequent answers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (443757 of 443757) |################| Elapsed Time: 0:00:01 Time:  0:00:01\n",
      "  0% (978 of 413036) |                   | Elapsed Time: 0:00:00 ETA:   0:00:42"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding weight list for id occurences..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (413036 of 413036) |################| Elapsed Time: 0:00:28 Time:  0:00:28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving processed datasets...\n",
      "Finished processing annotations and questions.\n",
      "val Dataset Loaded.\n",
      "val DataLoader loaded.\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"/auto/homes/bat34/VQA/\"\n",
    "ROOT_DIR = \"/auto/homes/bat34/VQA_PartII/\"\n",
    "MODEL_NAME = 'baseline'\n",
    "SPLIT = 'val'\n",
    "CONFIG_PATH = os.path.join(ROOT_DIR, MODEL_NAME, 'scripts', 'attention_baseline' + '.yaml')\n",
    "with open(CONFIG_PATH) as f:\n",
    "        config = yaml.load(f)\n",
    "        \n",
    "train_dataset = MurelNetDataset(split='train', \\\n",
    "                        txt_enc=config['txt_enc'], \\\n",
    "                        bottom_up_features_dir=config['bottom_up_features_dir'], \\\n",
    "                        skipthoughts_dir=config['skipthoughts_dir'], \\\n",
    "                        processed_dir=config['processed_dir'], \\\n",
    "                        ROOT_DIR=ROOT_DIR, \\\n",
    "                        vqa_dir=config['vqa_dir'])\n",
    "\n",
    "test_dataset = MurelNetDataset(split=SPLIT, \\\n",
    "                        txt_enc=config['txt_enc'], \\\n",
    "                        bottom_up_features_dir=config['bottom_up_features_dir'], \\\n",
    "                        skipthoughts_dir=config['skipthoughts_dir'], \\\n",
    "                        processed_dir=config['processed_dir'], \\\n",
    "                        ROOT_DIR=ROOT_DIR, \\\n",
    "                        vqa_dir=config['vqa_dir'])\n",
    "\n",
    "print('{} Dataset Loaded.'.format(SPLIT))\n",
    "\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, \\\n",
    "                         num_workers=config['num_workers'], \\\n",
    "                         batch_size=config['batch_size'] // 4, \\\n",
    "                         collate_fn=test_dataset.collate_fn, \\\n",
    ")\n",
    "\n",
    "print('{} DataLoader loaded.'.format(SPLIT))\n",
    "    \n",
    "word_vocabulary = [word for word, _ in train_dataset.word_to_wid.items()]\n",
    "#model = MurelNet(config, word_vocabulary)\n",
    "model = AttentionNet(config, word_vocabulary)\n",
    "\n",
    "BEST_MODEL_NAME = 'concat_baseline_self_attention_block_txt_enc_BayesianUniSkip_batch_size_256_lr_0.0001_lr_decay_rate_0.25_hidden_list_[1600, 1600]_attention_fusion_type_block_final_fusion_type_block'\n",
    "#BEST_MODEL_NAME = 'murel_reverse_question_object_txt_enc_BayesianUniSkip_batch_size_256_lr_5e-05_lr_decay_rate_0.25_unroll_steps_3_fusion_type_block'\n",
    "#BEST_MODEL_NAME_TEMPL = 'agg_concat_{}_agg_type_{}_q_self_attention_{}' + \\\n",
    "                  #'_txt_enc_BayesianUniSkip_batch_size_256_lr_0.0001_fusion_type_concat_mlp' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_train = iter(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'motorcycle',\n",
       " 'answer_id': tensor([72]),\n",
       " 'bounding_boxes': tensor([[0.0325, 0.0000, 0.9984, 0.4117],\n",
       "         [0.1439, 0.4076, 0.6005, 0.8460],\n",
       "         [0.3979, 0.2317, 0.6060, 0.4161],\n",
       "         [0.4424, 0.3983, 0.5688, 0.5770],\n",
       "         [0.4667, 0.1624, 0.5533, 0.2470],\n",
       "         [0.0020, 0.6714, 0.8951, 0.9983],\n",
       "         [0.4685, 0.6419, 0.9753, 0.8799],\n",
       "         [0.0262, 0.5853, 0.3379, 0.7079],\n",
       "         [0.0541, 0.5846, 0.1421, 0.7016],\n",
       "         [0.0140, 0.3480, 0.5992, 0.6229],\n",
       "         [0.1463, 0.5546, 0.4091, 0.9530],\n",
       "         [0.5583, 0.2612, 0.9523, 0.5546],\n",
       "         [0.0000, 0.0750, 0.3784, 0.3785],\n",
       "         [0.4652, 0.5463, 0.5774, 0.8386],\n",
       "         [0.6953, 0.2544, 0.9869, 0.5920],\n",
       "         [0.3452, 0.3473, 0.3861, 0.4051],\n",
       "         [0.0000, 0.1244, 0.3087, 0.4421],\n",
       "         [0.1935, 0.5260, 0.4488, 0.9465],\n",
       "         [0.0511, 0.2036, 0.7672, 0.4328],\n",
       "         [0.1337, 0.6075, 0.2064, 0.6792],\n",
       "         [0.3379, 0.1655, 0.6295, 0.6923],\n",
       "         [0.4713, 0.6221, 0.5829, 0.8662],\n",
       "         [0.4868, 0.3490, 0.5543, 0.4270],\n",
       "         [0.0000, 0.0000, 0.4799, 0.1915],\n",
       "         [0.0000, 0.0000, 0.3720, 0.5855],\n",
       "         [0.1914, 0.3321, 0.8253, 0.9983],\n",
       "         [0.0000, 0.5659, 0.1008, 0.7468],\n",
       "         [0.3171, 0.3916, 0.9059, 0.6896],\n",
       "         [0.0000, 0.5950, 0.0697, 0.7182],\n",
       "         [0.0468, 0.0000, 0.1856, 0.1825],\n",
       "         [0.4964, 0.3635, 0.5429, 0.4187],\n",
       "         [0.0000, 0.5221, 0.5494, 0.9983],\n",
       "         [0.3716, 0.4327, 0.5681, 0.8756],\n",
       "         [0.6167, 0.0000, 0.9984, 0.7468],\n",
       "         [0.5635, 0.9227, 0.9864, 0.9983],\n",
       "         [0.6281, 0.9533, 0.9042, 0.9983]]),\n",
       " 'id_unique': tensor([  72, 1280, 2229]),\n",
       " 'id_weights': tensor([0.4444, 0.3333, 0.2222]),\n",
       " 'image_name': 'COCO_train2014_000000131084.jpg',\n",
       " 'index': 31,\n",
       " 'object_features_list': tensor([[9.8892e-01, 0.0000e+00, 0.0000e+00,  ..., 4.0069e-01, 4.7450e+00,\n",
       "          1.3722e-01],\n",
       "         [0.0000e+00, 1.3047e-01, 6.0938e-03,  ..., 5.1264e+00, 0.0000e+00,\n",
       "          1.6733e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.0070e-01, 4.9764e+00,\n",
       "          1.5988e+00],\n",
       "         ...,\n",
       "         [3.6595e-01, 4.6150e-01, 0.0000e+00,  ..., 0.0000e+00, 2.5422e-01,\n",
       "          6.5728e-01],\n",
       "         [0.0000e+00, 5.6615e+00, 2.6770e+00,  ..., 0.0000e+00, 1.0052e+00,\n",
       "          3.9033e-02],\n",
       "         [0.0000e+00, 4.3378e+00, 4.6305e+00,  ..., 0.0000e+00, 4.5380e-01,\n",
       "          1.1762e-03]]),\n",
       " 'question_ids': tensor([ 441, 3751, 3815, 2330, 5628, 2308]),\n",
       " 'question_lengths': tensor([6]),\n",
       " 'question_type': 'what is the man',\n",
       " 'question_unique_id': 131084002}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.ones(1, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4444, 0.3333, 0.2222]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.index_select(1, x['id_unique']) * x['id_weights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['id_unique'].is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /auto/homes/bat34/VQA_PartII/baseline/trained_models/best_models/concat_baseline_self_attention_block_txt_enc_BayesianUniSkip_batch_size_256_lr_0.0001_lr_decay_rate_0.25_hidden_list_[1600, 1600]_attention_fusion_type_block_final_fusion_type_block/best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3350/3350 [10:26<00:00,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to /auto/homes/bat34/VQA_PartII/baseline/attention_block_val-2015_results.json\n",
      "Done saving to /auto/homes/bat34/VQA_PartII/baseline/attention_block_val-2015_results.json\n"
     ]
    }
   ],
   "source": [
    "#BEST_MODEL_NAME = 'murel_reverse_question_object_txt_enc_BayesianUniSkip_pooling_agg_min_pairwise_agg_max_batch_size_256_lr_5e-05_lr_decay_rate_0.25_unroll_steps_3_fusion_type_block'\n",
    "#BEST_MODEL_NAME = 'murel_reverse_question_object_txt_enc_BayesianUniSkip_batch_size_256_lr_5e-05_lr_decay_rate_0.25_unroll_steps_3_fusion_type_block'\n",
    "BEST_MODEL_PATH = os.path.join(ROOT_DIR, MODEL_NAME, 'trained_models', 'best_models', BEST_MODEL_NAME, 'best_model.pth')\n",
    "RES_FILE_NAME = 'attention_block_{}-2015_results.json'.format(SPLIT)\n",
    "RES_FILE_PATH = os.path.join(ROOT_DIR, MODEL_NAME, RES_FILE_NAME)\n",
    "eval_model(model, BEST_MODEL_PATH, RES_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing agg_concat_mean_agg_type_mean_q_self_attention_True_txt_enc_BayesianUniSkip_batch_size_256_lr_0.0001_fusion_type_concat_mlp....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6997/6997 [21:27<00:00,  5.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to /auto/homes/bat34/VQA_PartII/baseline/agg_mean_q_att_True_test-2015_results.json\n",
      "Done saving to /auto/homes/bat34/VQA_PartII/baseline/agg_mean_q_att_True_test-2015_results.json\n",
      "Processing agg_concat_mean_agg_type_mean_q_self_attention_False_txt_enc_BayesianUniSkip_batch_size_256_lr_0.0001_fusion_type_concat_mlp....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6997/6997 [08:21<00:00, 13.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to /auto/homes/bat34/VQA_PartII/baseline/agg_mean_q_att_False_test-2015_results.json\n",
      "Done saving to /auto/homes/bat34/VQA_PartII/baseline/agg_mean_q_att_False_test-2015_results.json\n",
      "Processing agg_concat_max_agg_type_max_q_self_attention_True_txt_enc_BayesianUniSkip_batch_size_256_lr_0.0001_fusion_type_concat_mlp....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6997/6997 [08:15<00:00, 14.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to /auto/homes/bat34/VQA_PartII/baseline/agg_max_q_att_True_test-2015_results.json\n",
      "Done saving to /auto/homes/bat34/VQA_PartII/baseline/agg_max_q_att_True_test-2015_results.json\n",
      "Processing agg_concat_max_agg_type_max_q_self_attention_False_txt_enc_BayesianUniSkip_batch_size_256_lr_0.0001_fusion_type_concat_mlp....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6997/6997 [08:09<00:00, 14.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to /auto/homes/bat34/VQA_PartII/baseline/agg_max_q_att_False_test-2015_results.json\n",
      "Done saving to /auto/homes/bat34/VQA_PartII/baseline/agg_max_q_att_False_test-2015_results.json\n",
      "Processing agg_concat_min_agg_type_min_q_self_attention_True_txt_enc_BayesianUniSkip_batch_size_256_lr_0.0001_fusion_type_concat_mlp....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6997/6997 [08:00<00:00, 14.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to /auto/homes/bat34/VQA_PartII/baseline/agg_min_q_att_True_test-2015_results.json\n",
      "Done saving to /auto/homes/bat34/VQA_PartII/baseline/agg_min_q_att_True_test-2015_results.json\n",
      "Processing agg_concat_min_agg_type_min_q_self_attention_False_txt_enc_BayesianUniSkip_batch_size_256_lr_0.0001_fusion_type_concat_mlp....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6997/6997 [08:27<00:00, 13.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to /auto/homes/bat34/VQA_PartII/baseline/agg_min_q_att_False_test-2015_results.json\n",
      "Done saving to /auto/homes/bat34/VQA_PartII/baseline/agg_min_q_att_False_test-2015_results.json\n",
      "Processing agg_concat_sum_agg_type_sum_q_self_attention_True_txt_enc_BayesianUniSkip_batch_size_256_lr_0.0001_fusion_type_concat_mlp....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 3939/6997 [04:30<03:03, 16.66it/s]"
     ]
    }
   ],
   "source": [
    "aggs = ['mean', 'max', 'min', 'sum']\n",
    "q_atts = ['True', 'False']\n",
    "\n",
    "for agg in aggs:\n",
    "    for q_att in q_atts:\n",
    "        if q_att == 'True':\n",
    "            config['q_self_attention'] = True\n",
    "            config['fusion_mlp']['input_dims'][0] = 4800\n",
    "        else:\n",
    "            config['q_self_attention'] = False\n",
    "            config['fusion_mlp']['input_dims'][0] = 2400\n",
    "        model = AggConcatNet(config, word_vocabulary)\n",
    "        BEST_MODEL_NAME = BEST_MODEL_NAME_TEMPL.format(agg, agg, q_att)\n",
    "        BEST_MODEL_PATH = os.path.join(ROOT_DIR, MODEL_NAME, 'trained_models', 'best_models', \\\n",
    "                             BEST_MODEL_NAME, 'best_model.pth')\n",
    "        RESULTS_FILE_PATH = os.path.join(ROOT_DIR, MODEL_NAME, 'agg_{}_q_att_{}_test-2015_results.json'.format(agg, q_att))\n",
    "        eval_model(model, BEST_MODEL_PATH, RESULTS_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ROOT_DIR': '/auto/homes/bat34/VQA_PartII/baseline/',\n",
       " 'agg_type': 'min',\n",
       " 'batch_size': 256,\n",
       " 'bottom_up_features_dir': '/auto/homes/bat34/2018-04-27_bottom-up-attention_fixed_36/',\n",
       " 'checkpoint_every': 1,\n",
       " 'checkpoint_option': 'resume_last',\n",
       " 'dropout': 0.2,\n",
       " 'epochs': 25,\n",
       " 'fusion_block': {'chunks': 20,\n",
       "  'dropout_input': 0.1,\n",
       "  'dropout_prelin': 0.0,\n",
       "  'input_dims': [4800, 2048],\n",
       "  'mm_dim': 1000,\n",
       "  'output_dims': 3000,\n",
       "  'rank': 15,\n",
       "  'type': 'block'},\n",
       " 'fusion_mlp': {'dropout': 0.2,\n",
       "  'hidden_list': [3200, 3200],\n",
       "  'input_dims': [4800, 2048],\n",
       "  'out_dim': 3000},\n",
       " 'fusion_type': 'concat_mlp',\n",
       " 'gradual_warmup_steps': [1.0, 4.0, 7.0],\n",
       " 'log_every': 50,\n",
       " 'lr': 0.0001,\n",
       " 'lr_decay_epochs': [14, 24, 2],\n",
       " 'lr_decay_rate': 0.25,\n",
       " 'name': 'agg_concat_min',\n",
       " 'num_workers': 4,\n",
       " 'processed_dir': '/auto/homes/bat34/VQA_PartII/data/processed_splits/',\n",
       " 'q_att': {'q_linear0': {'input_dim': 2400, 'output_dim': 512},\n",
       "  'q_linear1': {'input_dim': 512, 'output_dim': 2}},\n",
       " 'q_self_attention': False,\n",
       " 'reduction_factor': 8,\n",
       " 'skipthoughts_dir': '/auto/homes/bat34/VQA_PartII/data/skipthoughts',\n",
       " 'txt_enc': 'BayesianUniSkip',\n",
       " 'vqa_dir': '/auto/homes/bat34/VQA'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "with torch.no_grad():\n",
    "    for data in tqdm.tqdm(test_loader):\n",
    "        item = {\\\n",
    "            'question_ids': data['question_ids'].cuda(), \\\n",
    "            'object_features_list': data['object_features_list'].cuda(), \\\n",
    "            'bounding_boxes': data['bounding_boxes'].cuda(), \\\n",
    "            'question_lengths': data['question_lengths'].cuda(), \\\n",
    "        }\n",
    "        inputs = item\n",
    "        qids = data['question_unique_id']\n",
    "        outputs = model(inputs)\n",
    "        values, ans_indices = torch.max(outputs, dim=1)\n",
    "        ans_indices = list(ans_indices)\n",
    "        ans_indices = [tsr.item() for tsr in ans_indices]\n",
    "        for qid, ans_idx in zip(qids, ans_indices):\n",
    "            results.append({\n",
    "                'question_id': int(qid),\n",
    "                'answer': test_dataset.aid_to_ans[ans_idx]\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RESULTS_FILE_PATH = os.path.join(ROOT_DIR, MODEL_NAME, '{}_test-2015_results.json'.format(BEST_MODEL_NAME))\n",
    "RESULTS_FILE_PATH = os.path.join(ROOT_DIR, MODEL_NAME, 'baseline_self_attention_block_test-2015_results.json')\n",
    "with open(RESULTS_FILE_PATH, 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_FILE_PATH = os.path.join(ROOT_DIR, MODEL_NAME, '{}_test-2015_results.json'.format(BEST_MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
